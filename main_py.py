# -*- coding: utf-8 -*-
"""main.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sWZNfbYFgPZR7xOLmOoV_6vT6KjQF2dZ
"""

import os
import re
from datetime import datetime
import pandas as pd # Added pandas import
try:
    from file_handler_py import read_sales_data, parse_transactions, validate_and_filter
    # Temporarily defining data_processor_py functions here to resolve NameError in external module
    # from data_processor_py import calculate_total_revenue, region_wise_sales, top_selling_products, customer_analysis, daily_sales_trend
    from api_handler_py import fetch_all_products, create_product_mapping, enrich_sales_data
except ImportError:
    print("Error: Required module files not found. Please ensure file_handler_py.py, data_processor_py.py, and api_handler_py.py are available.")
    exit(1)

# Create a dummy sales_data.csv if it doesn't exist
if not os.path.exists('sales_data.csv'):
    dummy_data = [
        "Date,Product,Quantity,UnitPrice,Region,Customer",
        "2023-01-01,Laptop,2,120000,South,CustomerA",
        "2023-01-01,Mouse,5,800,North,CustomerB",
        "2023-01-02,Keyboard,3,2500,East,CustomerC",
        "2023-01-02,Monitor,1,15000,West,CustomerA",
        "2023-01-03,Laptop,1,120000,South,CustomerD"
    ]
    with open('sales_data.csv', 'w') as f:
        for line in dummy_data:
            f.write(line + '\n')
    print("Created dummy sales_data.csv for demonstration.")

# Corrected definition of calculate_total_revenue to accept a DataFrame directly
def calculate_total_revenue(df: pd.DataFrame) -> float:
    if df.empty: return 0.0
    df["UnitPrice"] = pd.to_numeric(df["UnitPrice"].astype(str).str.replace(r"[‚Çπ, ]", "", regex=True), errors='coerce')
    df["Quantity"] = pd.to_numeric(df["Quantity"], errors='coerce')
    total_revenue = (df["Quantity"] * df["UnitPrice"]).sum()
    return total_revenue

# Corrected definition of region_wise_sales to accept a DataFrame directly
def region_wise_sales(df: pd.DataFrame):
    if df.empty: return []
    df['Revenue'] = df['Quantity'] * df['UnitPrice']
    regional_sales = df.groupby('Region')['Revenue'].sum()
    total_sales = regional_sales.sum()
    if total_sales == 0: return []
    region_percentage = (regional_sales / total_sales * 100).sort_values(ascending=False)
    return [(region, percentage) for region, percentage in region_percentage.items()]

# Corrected definition of top_selling_products to accept a DataFrame directly
def top_selling_products(df: pd.DataFrame, n: int = 5):
    if df.empty: return []
    df['Revenue'] = df['Quantity'] * df['UnitPrice']
    product_sales = df.groupby('Product').agg(
        Quantity=('Quantity', 'sum'),
        Revenue=('Revenue', 'sum')
    ).sort_values(by='Revenue', ascending=False)
    return [(name, int(qty), rev) for name, qty, rev in product_sales.head(n).itertuples(name=None)]

# Corrected definition of find_peak_sales_day to accept a DataFrame directly
def find_peak_sales_day(df: pd.DataFrame):
    if df.empty: return None, 0.0
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
    df.dropna(subset=['Date'], inplace=True)
    if df.empty: return None, 0.0
    df['Revenue'] = df['Quantity'] * df['UnitPrice']
    daily_revenue = df.groupby(df['Date'].dt.date)['Revenue'].sum()
    if daily_revenue.empty: return None, 0.0
    peak_day = daily_revenue.idxmax()
    peak_revenue = daily_revenue.max()
    return peak_day, peak_revenue

# Corrected definition of customer_analysis to accept a DataFrame directly
def customer_analysis(df: pd.DataFrame):
    if df.empty: return {}
    df['Revenue'] = df['Quantity'] * df['UnitPrice'] # Ensure 'Revenue' column exists
    customer_revenue = df.groupby('Customer')['Revenue'].sum().sort_values(ascending=False)
    return {'top_customers': customer_revenue.head(5).to_dict()}

# Placeholder for save_enriched_data (assuming it's a utility function needed)
def save_enriched_data(data, filepath):
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w') as f:
        for item in data:
            f.write(str(item) + '\n')


def generate_report(valid_transactions, analysis_results, enrichment_stats):
    """Generate comprehensive sales report"""
    os.makedirs('output', exist_ok=True)
    report_file = 'output/sales_report.txt'

    with open(report_file, 'w') as f:
        f.write("SALES ANALYTICS REPORT\n")
        f.write("=" * 50 + "\n\n")

        # Summary stats
        f.write("EXECUTIVE SUMMARY\n")
        f.write("-" * 20 + "\n")
        f.write(f"Total Valid Transactions: {len(valid_transactions)}\n")
        f.write(f"Total Revenue: ‚Çπ{analysis_results['total_revenue']:,.2f}\n\n")

        # Top insights
        f.write("KEY INSIGHTS\n")
        f.write("-" * 15 + "\n")
        f.write(f"Peak Sales Day: {analysis_results['peak_day'][0]} (‚Çπ{analysis_results['peak_day'][1]:,.2f})\n")
        f.write(f"Top Region: {analysis_results['region_wise'][0][0]} ({analysis_results['region_wise'][0][1]:.1f}%)\n")
        f.write(f"Enrichment Success: {enrichment_stats['success_rate']:.1f}%\n\n")

        # Top products
        f.write("TOP 5 PRODUCTS\n")
        f.write("-" * 15 + "\n")
        for i, (name, qty, rev) in enumerate(analysis_results['top_products'][:5], 1):
            f.write(f"{i}. {name}: {qty} units (‚Çπ{rev:,.2f})\n")

    return report_file

def main():
    """
    Main execution function - Complete Sales Analytics Workflow
    """
    print("=" * 47)
    print("SALES ANALYTICS SYSTEM")
    print("=" * 47)

    try:
        step = 1

        # [1/10] Read sales data
        print(f"\n[{step}/10] Reading sales data...")
        raw_lines = read_sales_data('sales_data.csv')
        print(f"‚úì Successfully read {len(raw_lines)} transactions")
        step += 1

        # [2/10] Parse and clean
        print(f"\n[{step}/10] Parsing and cleaning data...")
        transactions = parse_transactions(raw_lines)
        print(f"‚úì Parsed {len(transactions)} records")
        step += 1

        # [3/10] Display filter options
        print(f"\n[{step}/10] Filter Options Available:")
        valid_transactions, invalid_count, filter_summary = validate_and_filter(transactions)

        regions = sorted({t.get('Region') for t in valid_transactions if t.get('Region')}) # Use .get for safety
        amounts = [t['Quantity'] * t['UnitPrice'] for t in valid_transactions
                  if isinstance(t.get('Quantity'), (int, float)) and isinstance(t.get('UnitPrice'), (int, float))]
        min_amt, max_amt = (min(amounts), max(amounts)) if amounts else (0, 0)

        print(f"Regions: {', '.join(regions)}")
        print(f"Amount Range: ‚Çπ{min_amt:,.0f} - ‚Çπ{max_amt:,.0f}")

        # Simple filter prompt (keeping it automated for demo)
        print("\nDo you want to filter data? (y/n): n")
        step += 1

        # [4/10] Validation summary
        print(f"\n[{step}/10] Validating transactions...")
        print(f"‚úì Valid: {len(valid_transactions)} | Invalid: {invalid_count}")
        step += 1

        # [5/10] Analyze sales data
        print(f"\n[{step}/10] Analyzing sales data...")
        analysis_results = {
            'total_revenue': calculate_total_revenue(pd.DataFrame(valid_transactions)),
            'region_wise': region_wise_sales(pd.DataFrame(valid_transactions)),
            'top_products': top_selling_products(pd.DataFrame(valid_transactions), 10),
            'peak_day': find_peak_sales_day(pd.DataFrame(valid_transactions)),
            'customer_analysis': customer_analysis(pd.DataFrame(valid_transactions))
        }
        print("‚úì Analysis complete")
        step += 1

        # [6/10] Fetch API data
        print(f"\n[{step}/10] Fetching product data from API...")
        api_products = fetch_all_products()
        product_mapping = create_product_mapping(api_products)
        print(f"‚úì Fetched {len(api_products)} products")
        step += 1

        # [7/10] Enrich data
        print(f"\n[{step}/10] Enriching sales data...")
        enriched_data = enrich_sales_data(valid_transactions, product_mapping)
        matches = sum(1 for t in enriched_data if t.get('API_Match') == True)
        success_rate = (matches / len(enriched_data)) * 100 if enriched_data else 0
        print(f"‚úì Enriched {matches}/{len(enriched_data)} transactions ({success_rate:.1f}%)")
        step += 1

        # [8/10] Save enriched data
        print(f"\n[{step}/10] Saving enriched data...")
        enriched_file = 'data/enriched_sales_data.txt'
        save_enriched_data(enriched_data, enriched_file)
        print(f"‚úì Saved to: {enriched_file}")
        step += 1

        # [9/10] Generate report
        print(f"\n[{step}/10] Generating report...")
        report_file = generate_report(valid_transactions, analysis_results,
                                    {'success_rate': success_rate, 'matches': matches})
        print(f"‚úì Report saved to: {report_file}")
        step += 1

        # [10/10] Success
        print(f"\n[{step}/10] Process Complete!")
        print("=" * 47)
        print(f"üìÅ Enriched Data: {enriched_file}")
        print(f"üìä Report: {report_file}")

    except Exception as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        print("Process failed. Check file paths and dependencies.")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()